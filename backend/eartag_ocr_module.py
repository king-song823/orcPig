# -*- coding: utf-8 -*-
"""
çŒªè€³æ ‡è¯†åˆ«æ¨¡å— - ç‹¬ç«‹æ¨¡å—
ä¸“é—¨ç”¨äºè¯†åˆ«çŒªè€³æ ‡ä¸­çš„7ä½å’Œ8ä½æ•°å­—
åŸºäºdemo_eartag_ocr.pyçš„ç§‘å­¦æ–¹æ¡ˆ
"""

import logging
import cv2
import numpy as np
import re
from paddleocr import PaddleOCR

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class EartagOCR:
    """çŒªè€³æ ‡OCRè¯†åˆ«ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–OCRå¼•æ“ - åŸºäºdemo_eartag_ocr.pyçš„ä¼˜åŒ–å‚æ•°"""
        self.ocr = PaddleOCR(
            use_angle_cls=True,      # æ–‡æœ¬æ–¹å‘åˆ†ç±»
            lang='ch',               # ä¸­æ–‡+æ•°å­—
            use_gpu=False,           # CPU æ¨¡å¼
            det_db_thresh=0.05,      # è¿›ä¸€æ­¥é™ä½æ£€æµ‹é˜ˆå€¼ï¼Œæé«˜æ£€æµ‹æ•æ„Ÿåº¦
            det_db_box_thresh=0.2,   # è¿›ä¸€æ­¥é™ä½æ¡†é˜ˆå€¼
            det_db_unclip_ratio=3.0, # è¿›ä¸€æ­¥å¢åŠ æœªè£å‰ªæ¯”ä¾‹
            drop_score=0.05,         # è¿›ä¸€æ­¥é™ä½ç½®ä¿¡åº¦é˜ˆå€¼
            max_text_length=50,      # å¢åŠ æœ€å¤§æ–‡æœ¬é•¿åº¦
            show_log=False
        )
    
    def is_valid_eartag_number(self, text):
        """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„è€³æ ‡æ•°å­—ï¼ˆåŸºäºdemo_eartag_ocr.pyçš„éªŒè¯é€»è¾‘ï¼‰"""
        # æ¸…ç†æ–‡æœ¬ï¼Œåªä¿ç•™æ•°å­—å’Œå­—æ¯
        clean_text = ''.join(c for c in text if c.isalnum())
        
        # è€³æ ‡æ•°å­—é€šå¸¸çš„ç‰¹å¾ï¼š
        # 1. é•¿åº¦å¿…é¡»æ˜¯7ä½æˆ–8ä½
        # 2. ä¸»è¦åŒ…å«æ•°å­—
        # 3. å¯èƒ½åŒ…å«å°‘é‡å­—æ¯
        if len(clean_text) != 7 and len(clean_text) != 8:
            return False
        
        # æ•°å­—å æ¯”åº”è¯¥è¶…è¿‡70%
        digit_count = sum(1 for c in clean_text if c.isdigit())
        if digit_count / len(clean_text) < 0.7:
            return False
        
        # è¿‡æ»¤æ‰æ˜æ˜¾çš„æ—¥æœŸæ ¼å¼ï¼ˆå¦‚2025-08-0, 2025080ç­‰ï¼‰
        if self._is_date_format(clean_text):
            return False
        
        return True
    
    def _is_date_format(self, text):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæ—¥æœŸæ ¼å¼ï¼Œç”¨äºè¿‡æ»¤è¯¯è¯†åˆ«"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„æ—¥æœŸæ¨¡å¼
        date_patterns = [
            r'^20\d{2}[0-1]\d[0-3]\d$',  # 2025080 æ ¼å¼
            r'^20\d{2}-[0-1]\d-[0-3]\d$',  # 2025-08-0 æ ¼å¼
            r'^\d{4}-\d{2}-\d{1}$',  # 2025-08-0 æ ¼å¼
        ]
        
        for pattern in date_patterns:
            if re.match(pattern, text):
                return True
        
        # æ£€æŸ¥æ˜¯å¦ä»¥202å¼€å¤´ä¸”é•¿åº¦åˆé€‚ï¼ˆå¯èƒ½æ˜¯å¹´ä»½ï¼‰
        if text.startswith('202') and len(text) >= 6:
            return True
            
        return False
    
    def extract_eartag_numbers(self, text):
        """ä»æ–‡æœ¬ä¸­æå–å¯èƒ½çš„è€³æ ‡æ•°å­—ï¼ˆåŸºäºdemo_eartag_ocr.pyï¼‰"""
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¿ç»­çš„æ•°å­—åºåˆ—
        numbers = re.findall(r'\d{4,}', text)
        return numbers
    
    def extract_circular_rois(self, img):
        """æ£€æµ‹å¹¶æå–åœ†å½¢è€³æ ‡åŒºåŸŸï¼Œè¿”å›è£å‰ªåçš„ROIåˆ—è¡¨ã€‚
        ä¼˜å…ˆåªå¯¹è¿™äº›åœ†å½¢åŒºåŸŸè¿›è¡ŒOCRï¼Œè¿‡æ»¤å…¶ä»–åŒºåŸŸå¹²æ‰°ã€‚
        """
        try:
            if img is None:
                return []
            # è½¬ç°åº¦ä¸é™å™ª
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if len(img.shape) == 3 else img.copy()
            blur = cv2.GaussianBlur(gray, (7, 7), 1.5)
            # Hough åœ†æ£€æµ‹ - ç®€åŒ–å‚æ•°ä»¥æé«˜æ€§èƒ½
            param_sets = [
                (1.2, 50, 60, 20),  # åªä¿ç•™ä¸€ç»„å‚æ•°
            ]
            rois = []
            h, w = gray.shape[:2]
            for dp, minDist, param1, param2 in param_sets:
                circles = cv2.HoughCircles(
                    blur,
                    cv2.HOUGH_GRADIENT,
                    dp=dp,
                    minDist=min(h, w) // 8,
                    param1=param1,
                    param2=param2,
                    minRadius=min(h, w) // 12,
                    maxRadius=min(h, w) // 2,
                )
                if circles is not None:
                    circles = np.uint16(np.around(circles))
                    # åªä¿ç•™æœ€å¤š3ä¸ªåŠå¾„è¾ƒå¤§çš„åœ†ä»¥é¿å…è¶…æ—¶
                    sorted_circles = sorted(circles[0, :], key=lambda x: x[2], reverse=True)[:3]
                    for c in sorted_circles:
                        cx, cy, r = int(c[0]), int(c[1]), int(c[2])
                        # åˆ›å»ºåœ†å½¢æ©è†œ
                        mask = np.zeros_like(gray)
                        cv2.circle(mask, (cx, cy), r, 255, -1)
                        masked = cv2.bitwise_and(img, img, mask=mask)
                        # ä»¥åœ†ä¸ºä¸­å¿ƒè£å‰ªæ­£æ–¹å½¢ROIï¼Œå¸¦è¾¹è·
                        margin = int(r * 0.2)
                        x1 = max(0, cx - r - margin)
                        y1 = max(0, cy - r - margin)
                        x2 = min(w, cx + r + margin)
                        y2 = min(h, cy + r + margin)
                        roi = masked[y1:y2, x1:x2]
                        # è¿‡æ»¤æå°åŒºåŸŸ
                        if roi is not None and roi.size > 0 and roi.shape[0] > 20 and roi.shape[1] > 20:
                            rois.append(roi)
                if rois:
                    break
            return rois
        except Exception as e:
            logger.error(f"åœ†å½¢ROIæå–é”™è¯¯: {e}")
            return []
    
    def extract_numbers_from_mixed_text(self, text):
        """ä»æ··åˆæ–‡æœ¬ä¸­æå–7ä½å’Œ8ä½æ•°å­—"""
        import re
        # æå–æ‰€æœ‰è¿ç»­çš„æ•°å­—åºåˆ—
        numbers = re.findall(r'\d+', text)
        valid_numbers = []
        
        for num in numbers:
            if len(num) == 7 or len(num) == 8:
                valid_numbers.append(num)
        
        return valid_numbers
    
    def clean_text_for_eartag(self, text):
        """æ¸…ç†æ–‡æœ¬ï¼Œå»é™¤ä¸­æ–‡å­—ç¬¦å’Œç‰¹æ®Šç¬¦å·ï¼Œåªä¿ç•™æ•°å­—å’Œå­—æ¯"""
        import re
        # åªä¿ç•™æ•°å­—å’Œå­—æ¯
        cleaned = re.sub(r'[^\w]', '', text)
        # å»é™¤ä¸­æ–‡å­—ç¬¦ï¼ˆä¿ç•™æ•°å­—å’Œè‹±æ–‡å­—æ¯ï¼‰
        cleaned = re.sub(r'[^\x00-\x7F]', '', cleaned)
        return cleaned
    
    def post_process_eartag_numbers(self, numbers):
        """åå¤„ç†è€³æ ‡æ•°å­—ï¼Œè¿›è¡Œåˆç†æ€§æ£€æŸ¥å’Œä¿®æ­£ï¼ˆå‚è€ƒdemo_eartag_ocr.pyï¼‰"""
        processed_numbers = []
        
        for number, confidence in numbers:
            original_number = number
            processed_number = number
            
            # 1. æ£€æŸ¥æ•°å­—çš„åˆç†æ€§
            if len(processed_number) in [7, 8]:
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è¿‡å¤šé‡å¤æ•°å­—ï¼ˆå¯èƒ½è¯†åˆ«é”™è¯¯ï¼‰
                digit_counts = {}
                for digit in processed_number:
                    digit_counts[digit] = digit_counts.get(digit, 0) + 1
                
                # å¦‚æœæŸä¸ªæ•°å­—å‡ºç°è¶…è¿‡3æ¬¡ï¼Œå¯èƒ½æœ‰é—®é¢˜
                max_repeat = max(digit_counts.values())
                if max_repeat > 3:
                    logger.warning(f"âš ï¸ æ•°å­— {processed_number} åŒ…å«é‡å¤æ•°å­—è¿‡å¤šï¼Œå¯èƒ½è¯†åˆ«æœ‰è¯¯")
                    # å¯¹äºé‡å¤æ•°å­—è¿‡å¤šçš„æ•°å­—ï¼Œé™ä½å…¶ä¼˜å…ˆçº§ä½†ä¸å®Œå…¨æ’é™¤
                    confidence = confidence * 0.5
            
            processed_numbers.append((processed_number, confidence, original_number))
        
        return processed_numbers
    
    def detect_and_correct_rotation(self, img):
        """æ£€æµ‹å¹¶æ ¡æ­£å›¾åƒæ—‹è½¬"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img.copy()
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            
            # éœå¤«ç›´çº¿æ£€æµ‹
            lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
            
            if lines is not None and len(lines) > 0:
                # è®¡ç®—ä¸»è¦è§’åº¦
                angles = []
                for line in lines:
                    rho, theta = line[0]
                    angle = theta * 180 / np.pi
                    if angle > 90:
                        angle = angle - 180
                    angles.append(angle)
                
                # è®¡ç®—å¹³å‡è§’åº¦
                avg_angle = np.mean(angles)
                logger.info(f"ğŸ” æ£€æµ‹åˆ°æ—‹è½¬è§’åº¦: {avg_angle:.2f}åº¦")
                
                # å¦‚æœè§’åº¦å¤§äºé˜ˆå€¼ï¼Œè¿›è¡Œæ ¡æ­£
                if abs(avg_angle) > 5:
                    # è®¡ç®—æ—‹è½¬ä¸­å¿ƒ
                    height, width = gray.shape[:2]
                    center = (width // 2, height // 2)
                    
                    # åˆ›å»ºæ—‹è½¬çŸ©é˜µ
                    rotation_matrix = cv2.getRotationMatrix2D(center, -avg_angle, 1.0)
                    
                    # æ‰§è¡Œæ—‹è½¬
                    corrected = cv2.warpAffine(img, rotation_matrix, (width, height))
                    logger.info(f"âœ… å·²æ ¡æ­£æ—‹è½¬è§’åº¦: {avg_angle:.2f}åº¦")
                    return corrected
            
            return img
            
        except Exception as e:
            logger.error(f"æ—‹è½¬æ£€æµ‹é”™è¯¯: {e}")
            return img
    
    def preprocess_image_for_eartag(self, img):
        """ä¸“é—¨é’ˆå¯¹çŒªè€³æ ‡çš„å›¾åƒé¢„å¤„ç† - å¢å¼ºç‰ˆ"""
        try:
            # é¦–å…ˆè¿›è¡Œæ—‹è½¬æ£€æµ‹å’Œæ ¡æ­£
            corrected_img = self.detect_and_correct_rotation(img)
            
            # è½¬æ¢ä¸ºç°åº¦å›¾
            gray = cv2.cvtColor(corrected_img, cv2.COLOR_BGR2GRAY)
            
            # å¤šç§é¢„å¤„ç†æ–¹æ¡ˆï¼Œæé«˜8ä½æ•°å­—è¯†åˆ«ç‡
            preprocessed_images = []
            
            # æ–¹æ¡ˆ1: æ ‡å‡†å¤„ç†
            denoised1 = cv2.GaussianBlur(gray, (3, 3), 0)
            clahe1 = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            enhanced1 = clahe1.apply(denoised1)
            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened1 = cv2.filter2D(enhanced1, -1, kernel)
            binary1 = cv2.adaptiveThreshold(sharpened1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            preprocessed_images.append(binary1)
            
            # æ–¹æ¡ˆ2: å¼ºå¯¹æ¯”åº¦å¤„ç†ï¼ˆé’ˆå¯¹æ¨¡ç³Šçš„8ä½æ•°å­—ï¼‰
            denoised2 = cv2.GaussianBlur(gray, (5, 5), 0)
            clahe2 = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(6, 6))
            enhanced2 = clahe2.apply(denoised2)
            # æ›´å¼ºçš„é”åŒ–
            kernel_strong = np.array([[-2,-2,-2], [-2,17,-2], [-2,-2,-2]])
            sharpened2 = cv2.filter2D(enhanced2, -1, kernel_strong)
            binary2 = cv2.adaptiveThreshold(sharpened2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 3)
            preprocessed_images.append(binary2)
            
            # æ–¹æ¡ˆ3: ä¼½é©¬æ ¡æ­£ + åŒè¾¹æ»¤æ³¢
            gamma = 1.3
            lookup_table = np.array([((i / 255.0) ** (1.0 / gamma)) * 255 for i in np.arange(0, 256)]).astype("uint8")
            gamma_corrected = cv2.LUT(gray, lookup_table)
            bilateral = cv2.bilateralFilter(gamma_corrected, 9, 75, 75)
            binary3 = cv2.adaptiveThreshold(bilateral, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 13, 2)
            preprocessed_images.append(binary3)
            
            # æ–¹æ¡ˆ4: å¯¹æ¯”åº¦å¢å¼º
            enhanced4 = cv2.convertScaleAbs(gray, alpha=1.8, beta=40)
            denoised4 = cv2.GaussianBlur(enhanced4, (3, 3), 0)
            binary4 = cv2.adaptiveThreshold(denoised4, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 9, 2)
            preprocessed_images.append(binary4)
            
            # æ–¹æ¡ˆ5: å½¢æ€å­¦å¢å¼º
            denoised5 = cv2.GaussianBlur(gray, (3, 3), 0)
            clahe5 = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(7, 7))
            enhanced5 = clahe5.apply(denoised5)
            # å¼€è¿ç®—å»é™¤å™ªç‚¹
            kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
            opened = cv2.morphologyEx(enhanced5, cv2.MORPH_OPEN, kernel_open)
            binary5 = cv2.adaptiveThreshold(opened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
            preprocessed_images.append(binary5)
            
            # å¯¹æ¯ä¸ªé¢„å¤„ç†å›¾åƒè¿›è¡Œå½¢æ€å­¦æ“ä½œ
            final_images = []
            for binary in preprocessed_images:
                # å½¢æ€å­¦æ“ä½œï¼Œå»é™¤å™ªç‚¹
                kernel = np.ones((2, 2), np.uint8)
                cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
                cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
                
                # ç¡®ä¿å›¾åƒæ˜¯3é€šé“çš„ï¼Œå› ä¸ºPaddleOCRæœŸæœ›å½©è‰²å›¾åƒ
                if len(cleaned.shape) == 2:
                    cleaned = cv2.cvtColor(cleaned, cv2.COLOR_GRAY2BGR)
                
                final_images.append(cleaned)
            
            return final_images
            
        except Exception as e:
            logger.error(f"çŒªè€³æ ‡å›¾åƒé¢„å¤„ç†é”™è¯¯: {e}")
            return [img]
    
    def create_rotated_images(self, img, angles=[0, 90, 180, 270]):
        """åˆ›å»ºå¤šä¸ªæ—‹è½¬è§’åº¦çš„å›¾åƒç”¨äºè¯†åˆ«é¢ å€’çš„æ•°å­—ï¼ˆåŸºäºdemo_eartag_ocr.pyï¼‰"""
        rotated_images = []
        for angle in angles:
            if angle == 0:
                rotated_images.append(img)
            else:
                # è®¡ç®—æ—‹è½¬ä¸­å¿ƒ
                height, width = img.shape[:2]
                center = (width // 2, height // 2)
                
                # åˆ›å»ºæ—‹è½¬çŸ©é˜µ
                rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
                
                # æ‰§è¡Œæ—‹è½¬
                rotated = cv2.warpAffine(img, rotation_matrix, (width, height))
                rotated_images.append(rotated)
        
        return rotated_images
    
    def enhance_image_for_blur_detection(self, img):
        """ä¸“é—¨é’ˆå¯¹æ¨¡ç³Šå›¾åƒçš„å¢å¼ºå¤„ç†"""
        try:
            # è½¬æ¢ä¸ºç°åº¦å›¾
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img.copy()
            
            # 1. åº”ç”¨CLAHEå¢å¼ºå¯¹æ¯”åº¦ï¼ˆæ›´å¼ºï¼‰
            clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))
            enhanced = clahe.apply(gray)
            
            # 2. é«˜æ–¯æ¨¡ç³Šå»å™ª
            denoised = cv2.GaussianBlur(enhanced, (3, 3), 0)
            
            # 3. é”åŒ–å¤„ç†
            kernel_sharpen = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
            sharpened = cv2.filter2D(denoised, -1, kernel_sharpen)
            
            # 4. è‡ªé€‚åº”é˜ˆå€¼äºŒå€¼åŒ–ï¼ˆé’ˆå¯¹æ¨¡ç³Šå›¾åƒä¼˜åŒ–ï¼‰
            binary = cv2.adaptiveThreshold(sharpened, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 5)
            
            # 5. å½¢æ€å­¦æ“ä½œï¼šé—­è¿ç®—è¿æ¥æ–­å¼€çš„ç¬”ç”»
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            closed = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
            
            # 6. å½¢æ€å­¦æ“ä½œï¼šå¼€è¿ç®—å»é™¤å°å™ªç‚¹
            kernel_open = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
            cleaned = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel_open)
            
            # ç¡®ä¿å›¾åƒæ˜¯3é€šé“çš„
            if len(cleaned.shape) == 2:
                cleaned = cv2.cvtColor(cleaned, cv2.COLOR_GRAY2BGR)
            
            return cleaned
            
        except Exception as e:
            logger.error(f"æ¨¡ç³Šå›¾åƒå¢å¼ºé”™è¯¯: {e}")
            return img
    
    def enhanced_ocr_image_for_eartag(self, image_bytes):
        """å¢å¼ºç‰ˆçŒªè€³æ ‡OCRè¯†åˆ« - åŸºäºdemo_eartag_ocr.pyçš„å¤šè§’åº¦ç­–ç•¥"""
        try:
            # è§£ç å›¾åƒ
            nparr = np.frombuffer(image_bytes, np.uint8)
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if img is None:
                logger.error("âŒ æ— æ³•è§£ç å›¾åƒ")
                return []
            
            all_results = []
            
            # === ç¬¬ä¸€å±‚ï¼šåŸå›¾è¯†åˆ« ===
            logger.info("ğŸ· ã€ç¬¬ä¸€å±‚ã€‘åŸå›¾è¯†åˆ«...")
            try:
                result_original = self.ocr.ocr(img, det=True, rec=True)
                if result_original:
                    all_results.extend(result_original)
            except Exception as e:
                logger.warning(f"åŸå›¾OCRå¤±è´¥: {e}")
            
            # === ç¬¬äºŒå±‚ï¼šé¢„å¤„ç†å›¾åƒè¯†åˆ« ===
            logger.info("ğŸ· ã€ç¬¬äºŒå±‚ã€‘é¢„å¤„ç†å›¾åƒè¯†åˆ«...")
            try:
                # ä½¿ç”¨demo_eartag_ocr.pyçš„é¢„å¤„ç†æ–¹æ³•
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                enhanced = clahe.apply(gray)
                denoised = cv2.GaussianBlur(enhanced, (3, 3), 0)
                binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
                cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
                
                result_processed = self.ocr.ocr(cleaned, det=True, rec=True)
                if result_processed:
                    all_results.extend(result_processed)
            except Exception as e:
                logger.warning(f"é¢„å¤„ç†OCRå¤±è´¥: {e}")
            
            # === ç¬¬ä¸‰å±‚ï¼šå¤šè§’åº¦æ—‹è½¬è¯†åˆ«ï¼ˆdemo_eartag_ocr.pyçš„æ ¸å¿ƒä¼˜åŠ¿ï¼‰===
            logger.info("ğŸ· ã€ç¬¬ä¸‰å±‚ã€‘å¤šè§’åº¦æ—‹è½¬è¯†åˆ«...")
            try:
                rotated_images = self.create_rotated_images(img, [90, 180, 270])
                
                for rotated_img in rotated_images:
                    try:
                        result_rotated = self.ocr.ocr(rotated_img, det=True, rec=True)
                        if result_rotated:
                            all_results.extend(result_rotated)
                    except Exception as e:
                        logger.warning(f"æ—‹è½¬å›¾åƒOCRå¤±è´¥: {e}")
                
                logger.info("ğŸ· å¤šè§’åº¦æ—‹è½¬è¯†åˆ«å®Œæˆ")
            except Exception as e:
                logger.warning(f"å¤šè§’åº¦æ—‹è½¬è¯†åˆ«å¤±è´¥: {e}")
            
            # å¤„ç†è¯†åˆ«ç»“æœ
            unique_results = []
            seen_texts = set()
            
            for result in all_results:
                if result and len(result) > 0:
                    for line in result:
                        if len(line) >= 2:
                            text = line[1][0] if isinstance(line[1], (list, tuple)) else str(line[1])
                            confidence = line[1][1] if isinstance(line[1], (list, tuple)) and len(line[1]) > 1 else 0.5
                            bbox = line[0] if len(line) > 0 else None
                            
                            # æ¸…ç†æ–‡æœ¬ç”¨äºå»é‡
                            clean_text = ''.join(c for c in text if c.isalnum())
                            
                            if clean_text not in seen_texts:
                                unique_results.append({
                                    "text": text,
                                    "confidence": confidence,
                                    "bbox": bbox
                                })
                                seen_texts.add(clean_text)
            
            logger.info(f"âœ… çŒªè€³æ ‡å¤šè§’åº¦OCRè¯†åˆ«åˆ° {len(unique_results)} ä¸ªæ–‡æœ¬å—")
            return unique_results
            
        except Exception as e:
            logger.error(f"çŒªè€³æ ‡OCRè¯†åˆ«é”™è¯¯: {e}")
            return []
    
    def extract_pig_ear_tag_enhanced(self, texts_with_boxes):
        """æå–çŒªè€³æ ‡ä¸­çš„è€³æ ‡å·ç  - åŸºäºdemo_eartag_ocr.pyçš„ä¼˜åŒ–æ–¹æ¡ˆ"""
        # åˆå§‹åŒ–ç»“æœ
        result = {
            "ear_tag_7digit": "æœªè¯†åˆ«",  # 7ä½è€³æ ‡å·ç 
            "ear_tag_8digit": "æœªè¯†åˆ«",  # 8ä½è€³æ ‡å·ç 
        }
        
        # åˆ†ç±»å­˜å‚¨ç»“æœ
        eartag_numbers = []      # è€³æ ‡æ•°å­—
        other_numbers = []       # å…¶ä»–æ•°å­—
        text_content = []        # æ–‡æœ¬å†…å®¹
        
        # å¤„ç†æ‰€æœ‰è¯†åˆ«ç»“æœï¼Œè¿›è¡Œåˆ†ç±»
        for word_info in texts_with_boxes:
            try:
                text = word_info["text"]        # è¯†åˆ«çš„æ–‡å­—
                confidence = word_info.get("confidence", 0.0)  # ç½®ä¿¡åº¦
                
                # æ¸…ç†æ–‡æœ¬ï¼Œåªä¿ç•™æ•°å­—å’Œå­—æ¯
                clean_text = ''.join(c for c in text if c.isalnum())
                
                # åˆ†ç±»å¤„ç† - åŸºäºdemo_eartag_ocr.pyçš„é€»è¾‘
                if self.is_valid_eartag_number(clean_text):
                    eartag_numbers.append((clean_text, confidence))
                    logger.info(f"ğŸ¯ è¯†åˆ«åˆ°è€³æ ‡æ•°å­—: '{clean_text}' (ç½®ä¿¡åº¦: {confidence:.4f})")
                elif any(c.isdigit() for c in text):
                    # æ··åˆæ–‡æœ¬ï¼Œå…ˆå°è¯•æå–çº¯æ•°å­—
                    extracted_numbers = self.extract_eartag_numbers(text)
                    if extracted_numbers:
                        # å¦‚æœæå–åˆ°æœ‰æ•ˆæ•°å­—ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºè€³æ ‡æ•°å­—
                        for num in extracted_numbers:
                            if self.is_valid_eartag_number(num):
                                eartag_numbers.append((num, confidence))
                                logger.info(f"ğŸ”§ ä»æ··åˆæ–‡æœ¬ '{text}' æå–è€³æ ‡æ•°å­—: {num}")
                            else:
                                other_numbers.append((num, confidence))
                    else:
                        other_numbers.append((text, confidence))
                else:
                    text_content.append((text, confidence))
                    
            except Exception as e:
                logger.warning(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"ğŸ” è€³æ ‡æ•°å­—å€™é€‰: {[num[0] for num in eartag_numbers]}")
        logger.info(f"ğŸ” å…¶ä»–æ•°å­—å€™é€‰: {[num[0] for num in other_numbers]}")
        logger.info(f"ğŸ” è¯¦ç»†è€³æ ‡æ•°å­—å€™é€‰: {eartag_numbers}")
        
        # æŒ‰ç½®ä¿¡åº¦æ’åºè€³æ ‡æ•°å­—
        eartag_numbers.sort(key=lambda x: x[1], reverse=True)
        logger.info(f"ğŸ” æ’åºåçš„è€³æ ‡æ•°å­—: {eartag_numbers}")
        
        # å»é‡å¹¶æå–æœ€å¯èƒ½çš„ä¸¤ä¸ªæ•°å­—
        seen_numbers = set()
        valid_eartag_numbers = []
        
        for text, confidence in eartag_numbers:
            clean_text = ''.join(c for c in text if c.isalnum())
            if clean_text not in seen_numbers and len(clean_text) in [7, 8]:
                valid_eartag_numbers.append((clean_text, confidence))
                seen_numbers.add(clean_text)
        
        logger.info(f"ğŸ” æœ‰æ•ˆè€³æ ‡æ•°å­—: {valid_eartag_numbers}")
        print(f"ğŸ” DEBUG: æœ‰æ•ˆè€³æ ‡æ•°å­—: {valid_eartag_numbers}")
        
        # åº”ç”¨åå¤„ç†ä¼˜åŒ–ï¼ˆå‚è€ƒdemo_eartag_ocr.pyï¼‰
        if valid_eartag_numbers:
            logger.info("ğŸ”§ åº”ç”¨åå¤„ç†ä¼˜åŒ–...")
            processed_numbers = self.post_process_eartag_numbers(valid_eartag_numbers)
            # æ›´æ–°ä¸ºå¤„ç†åçš„æ•°å­—
            valid_eartag_numbers = [(num, conf) for num, conf, orig in processed_numbers]
            logger.info(f"ğŸ”§ åå¤„ç†åçš„è€³æ ‡æ•°å­—: {valid_eartag_numbers}")
            print(f"ğŸ” DEBUG: åå¤„ç†åçš„è€³æ ‡æ•°å­—: {valid_eartag_numbers}")
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºæœ€ç»ˆçš„æ•°å­—åˆ†é…é€»è¾‘
        logger.info(f"ğŸ” å¼€å§‹æ•°å­—åˆ†é…ï¼Œæœ‰æ•ˆæ•°å­—æ•°é‡: {len(valid_eartag_numbers)}")
        
        # é€‰æ‹©æœ€å¯èƒ½çš„ä¸¤ä¸ªæ•°å­— - æ™ºèƒ½åˆ†é…ç­–ç•¥
        if len(valid_eartag_numbers) >= 2:
            # æŒ‰é•¿åº¦åˆ†ç±»
            seven_digit_candidates = [(num, conf) for num, conf in valid_eartag_numbers if len(num) == 7]
            eight_digit_candidates = [(num, conf) for num, conf in valid_eartag_numbers if len(num) == 8]
            
            print(f"ğŸ” DEBUG: 7ä½å€™é€‰: {seven_digit_candidates}")
            print(f"ğŸ” DEBUG: 8ä½å€™é€‰: {eight_digit_candidates}")
            
            # ä¼˜å…ˆé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„7ä½å’Œ8ä½æ•°å­—
            if seven_digit_candidates and eight_digit_candidates:
                # æœ‰7ä½å’Œ8ä½æ•°å­—ï¼Œä¼˜å…ˆé€‰æ‹©ä»¥"1"å¼€å¤´çš„7ä½æ•°å­—
                best_8digit = max(eight_digit_candidates, key=lambda x: x[1])
                
                # ä¼˜å…ˆé€‰æ‹©ä»¥"1"å¼€å¤´çš„7ä½æ•°å­—
                one_start_candidates = [c for c in seven_digit_candidates if c[0].startswith('1')]
                if one_start_candidates:
                    best_7digit = max(one_start_candidates, key=lambda x: x[1])
                    print(f"âœ… DEBUG: ä¼˜å…ˆé€‰æ‹©1å¼€å¤´çš„7ä½æ•°å­— - 7ä½: {best_7digit[0]}, 8ä½: {best_8digit[0]}")
                else:
                    # å¦‚æœæ²¡æœ‰ä»¥"1"å¼€å¤´çš„ï¼Œé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„
                    best_7digit = max(seven_digit_candidates, key=lambda x: x[1])
                    print(f"âš ï¸ DEBUG: æ— 1å¼€å¤´çš„7ä½æ•°å­—ï¼Œé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ - 7ä½: {best_7digit[0]}, 8ä½: {best_8digit[0]}")
                
                result["ear_tag_7digit"] = best_7digit[0]
                result["ear_tag_8digit"] = best_8digit[0]
            elif seven_digit_candidates:
                # åªæœ‰7ä½æ•°å­—ï¼Œä¼˜å…ˆé€‰æ‹©ä»¥"1"å¼€å¤´çš„
                one_start_candidates = [c for c in seven_digit_candidates if c[0].startswith('1')]
                if one_start_candidates:
                    # ä¼˜å…ˆé€‰æ‹©ä»¥"1"å¼€å¤´çš„7ä½æ•°å­—
                    seven_digit_candidates = one_start_candidates
                    print(f"âœ… DEBUG: ä¼˜å…ˆé€‰æ‹©1å¼€å¤´çš„7ä½æ•°å­—")
                
                seven_digit_candidates.sort(key=lambda x: x[1], reverse=True)
                result["ear_tag_7digit"] = seven_digit_candidates[0][0]
                if len(seven_digit_candidates) > 1:
                    # ç¬¬äºŒä¸ª7ä½æ•°å­—è¡¥é›¶å˜æˆ8ä½
                    result["ear_tag_8digit"] = seven_digit_candidates[1][0] + "0"
                else:
                    # åªæœ‰ä¸€ä¸ª7ä½æ•°å­—ï¼Œè¡¥é›¶å˜æˆ8ä½
                    result["ear_tag_8digit"] = seven_digit_candidates[0][0] + "0"
                print(f"âœ… DEBUG: 7ä½æ•°å­—ç­–ç•¥ - 7ä½: {result['ear_tag_7digit']}, 8ä½: {result['ear_tag_8digit']}")
            elif eight_digit_candidates:
                # åªæœ‰8ä½æ•°å­—ï¼Œé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ä¸¤ä¸ª
                eight_digit_candidates.sort(key=lambda x: x[1], reverse=True)
                result["ear_tag_8digit"] = eight_digit_candidates[0][0]
                if len(eight_digit_candidates) > 1:
                    # ç¬¬äºŒä¸ª8ä½æ•°å­—æˆªå–å‰7ä½
                    result["ear_tag_7digit"] = eight_digit_candidates[1][0][:7]
                else:
                    # åªæœ‰ä¸€ä¸ª8ä½æ•°å­—ï¼Œæˆªå–å‰7ä½
                    result["ear_tag_7digit"] = eight_digit_candidates[0][0][:7]
                print(f"âœ… DEBUG: 8ä½æ•°å­—ç­–ç•¥ - 7ä½: {result['ear_tag_7digit']}, 8ä½: {result['ear_tag_8digit']}")
            else:
                # å…¶ä»–æƒ…å†µï¼ŒæŒ‰ç½®ä¿¡åº¦åˆ†é…
                first_num = valid_eartag_numbers[0][0]
                second_num = valid_eartag_numbers[1][0]
                print(f"ğŸ” DEBUG: æŒ‰é•¿åº¦åˆ†é… - first: {first_num}, second: {second_num}")
                
                if len(first_num) == 7 and len(second_num) == 8:
                    result["ear_tag_7digit"] = first_num
                    result["ear_tag_8digit"] = second_num
                elif len(first_num) == 8 and len(second_num) == 7:
                    result["ear_tag_7digit"] = second_num
                    result["ear_tag_8digit"] = first_num
                else:
                    # å…¶ä»–æƒ…å†µï¼Œä¼˜å…ˆä½¿ç”¨7ä½æ•°å­—
                    for num, conf in valid_eartag_numbers:
                        if len(num) == 7 and result["ear_tag_7digit"] == "æœªè¯†åˆ«":
                            result["ear_tag_7digit"] = num
                        elif len(num) == 8 and result["ear_tag_8digit"] == "æœªè¯†åˆ«":
                            result["ear_tag_8digit"] = num
                
        elif len(valid_eartag_numbers) == 1:
            # åªæœ‰ä¸€ä¸ªæœ‰æ•ˆæ•°å­—
            num = valid_eartag_numbers[0][0]
            if len(num) == 7:
                result["ear_tag_7digit"] = num
                result["ear_tag_8digit"] = num + "0"
            elif len(num) == 8:
                result["ear_tag_7digit"] = num[:7]
                result["ear_tag_8digit"] = num
            else:
                result["ear_tag_7digit"] = num
                result["ear_tag_8digit"] = "æœªè¯†åˆ«"
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»å…¶ä»–æ•°å­—ä¸­å¯»æ‰¾
        if result["ear_tag_7digit"] == "æœªè¯†åˆ«" or result["ear_tag_8digit"] == "æœªè¯†åˆ«":
            other_valid_numbers = []
            for text, confidence in other_numbers:
                clean_text = ''.join(c for c in text if c.isalnum())
                if len(clean_text) in [7, 8] and clean_text not in seen_numbers:
                    other_valid_numbers.append((clean_text, confidence))
            
            other_valid_numbers.sort(key=lambda x: x[1], reverse=True)
            
            if other_valid_numbers:
                for num, confidence in other_valid_numbers:
                    if result["ear_tag_7digit"] == "æœªè¯†åˆ«" and len(num) == 7:
                        result["ear_tag_7digit"] = num
                    elif result["ear_tag_8digit"] == "æœªè¯†åˆ«" and len(num) == 8:
                        result["ear_tag_8digit"] = num
                    elif result["ear_tag_7digit"] == "æœªè¯†åˆ«" and len(num) == 8:
                        result["ear_tag_7digit"] = num[:7]
                    elif result["ear_tag_8digit"] == "æœªè¯†åˆ«" and len(num) == 7:
                        result["ear_tag_8digit"] = num + "0"
        
        logger.info(f"ğŸ“Œ ç§‘å­¦çŒªè€³æ ‡æå–ç»“æœ: {result}")
        print(f"ğŸ” DEBUG: æœ€ç»ˆç»“æœ - 7ä½: {result['ear_tag_7digit']}, 8ä½: {result['ear_tag_8digit']}")
        return result
    
    def recognize_eartag(self, image_bytes):
        """çŒªè€³æ ‡è¯†åˆ«ä¸»å‡½æ•°"""
        try:
            # æ‰§è¡Œå¢å¼ºOCRè¯†åˆ«
            texts_with_boxes = self.enhanced_ocr_image_for_eartag(image_bytes)
            
            if not texts_with_boxes:
                logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°ä»»ä½•æ–‡æœ¬")
                return {
                    "ear_tag_7digit": "æœªè¯†åˆ«",
                    "ear_tag_8digit": "æœªè¯†åˆ«"
                }
            
            # æå–è€³æ ‡æ•°å­—
            result = self.extract_pig_ear_tag_enhanced(texts_with_boxes)
            return result
            
        except Exception as e:
            logger.error(f"çŒªè€³æ ‡è¯†åˆ«é”™è¯¯: {e}")
            return {
                "ear_tag_7digit": "æœªè¯†åˆ«",
                "ear_tag_8digit": "æœªè¯†åˆ«"
            }

# åˆ›å»ºå…¨å±€å®ä¾‹
eartag_ocr = EartagOCR()

def recognize_pig_ear_tag(image_bytes):
    """çŒªè€³æ ‡è¯†åˆ«æ¥å£å‡½æ•°"""
    return eartag_ocr.recognize_eartag(image_bytes)
